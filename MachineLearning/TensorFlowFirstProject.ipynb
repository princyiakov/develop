{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 19.2.3\n",
      "    Uninstalling pip-19.2.3:\n",
      "      Successfully uninstalled pip-19.2.3\n",
      "Successfully installed pip-20.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.1.0-cp37-cp37m-win_amd64.whl (355.8 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\princy\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\princy\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.5)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\princy\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.6)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9 MB)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.26.0-cp37-cp37m-win_amd64.whl (1.8 MB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.1.8-py3-none-any.whl (57 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.1.0.tar.gz (69 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Using cached tensorboard-2.1.0-py3-none-any.whl (3.8 MB)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Using cached tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Using cached protobuf-3.11.2-cp37-cp37m-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\princy\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\princy\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\princy\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (41.4.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.1.1-py2.py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\princy\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\princy\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.11.0-py2.py3-none-any.whl (76 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\princy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\princy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\princy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\princy\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.9.11)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Using cached rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: gast, termcolor, opt-einsum, absl-py\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7547 sha256=4258d68023b12c619c33f219fef1c8c49846bf8ee8c23ae20fa7229bc59928e8\n",
      "  Stored in directory: c:\\users\\princy\\appdata\\local\\pip\\cache\\wheels\\21\\7f\\02\\420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=52d804e091bb3ddf267fa287bcdbd2977a1b655c22cc4b5d3bca745b2bb0c9ef\n",
      "  Stored in directory: c:\\users\\princy\\appdata\\local\\pip\\cache\\wheels\\3f\\e3\\ec\\8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for opt-einsum (setup.py): started\n",
      "  Building wheel for opt-einsum (setup.py): finished with status 'done'\n",
      "  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-py3-none-any.whl size=61699 sha256=57ffcfbeac8e5bdeda56f399173f27d6da3baae691eb2488a1f579d2df613b85\n",
      "  Stored in directory: c:\\users\\princy\\appdata\\local\\pip\\cache\\wheels\\21\\e3\\31\\0d3919995e859eff01713d381aac3b6b43c69915a2942e5c65\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121935 sha256=c0e997de4deef948c0f4544477123363c6d4e8643b5fddee3f3ec788e131ff2c\n",
      "  Stored in directory: c:\\users\\princy\\appdata\\local\\pip\\cache\\wheels\\cc\\af\\1a\\498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
      "Successfully built gast termcolor opt-einsum absl-py\n",
      "Installing collected packages: keras-applications, keras-preprocessing, scipy, gast, astor, grpcio, google-pasta, termcolor, opt-einsum, absl-py, protobuf, oauthlib, requests-oauthlib, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, markdown, tensorboard, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.3.1\n",
      "    Uninstalling scipy-1.3.1:\n",
      "      Successfully uninstalled scipy-1.3.1\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.0.0 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.26.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 oauthlib-3.1.0 opt-einsum-3.1.0 protobuf-3.11.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 18s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# To load data into training and testing format \n",
    "(x_train, y_train) , (x_test, y_test) = mnist_data.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data integers to floating-point numbers\n",
    "x_train , x_test = x_train/255.0 , x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0288 - accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08427973033208327, 0.9795]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=1)\n",
    "model.evaluate(x_test,  y_test, verbose=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
